{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import ViltProcessor, ViltModel, BertModel\n",
    "# model = BertModel.from_pretrained(\"hfl/bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load image processor for 'dandelin/vilt-b32-mlm'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'dandelin/vilt-b32-mlm' is the correct path to a directory containing a preprocessor_config.json file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.10/site-packages/transformers/image_processing_utils.py:269\u001b[0m, in \u001b[0;36mImageProcessingMixin.get_image_processor_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     resolved_image_processor_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    270\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    271\u001b[0m         image_processor_file,\n\u001b[1;32m    272\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    273\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    274\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    275\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    276\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    277\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    278\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    279\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    280\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[39m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[39m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.10/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    418\u001b[0m         path_or_repo_id,\n\u001b[1;32m    419\u001b[0m         filename,\n\u001b[1;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:120\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.10/site-packages/huggingface_hub/file_download.py:1256\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[39mif\u001b[39;00m force_download:\n\u001b[0;32m-> 1256\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1257\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWe have no connection or you passed local_files_only, so force_download is not an accepted option.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[1;32m   1260\u001b[0m \u001b[39m# Try to get \"commit_hash\" from \"revision\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: We have no connection or you passed local_files_only, so force_download is not an accepted option.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(requests\u001b[39m.\u001b[39mget(url, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mraw)\n\u001b[1;32m      8\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhello world\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m processor \u001b[39m=\u001b[39m ViltProcessor\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mdandelin/vilt-b32-mlm\u001b[39;49m\u001b[39m\"\u001b[39;49m, force_download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     11\u001b[0m model \u001b[39m=\u001b[39m ViltModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mdandelin/vilt-b32-mlm\u001b[39m\u001b[39m\"\u001b[39m, force_download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# inputs = processor(None, text, return_tensors=\"pt\")\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# outputs = model(**inputs)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# last_hidden_states = outputs.last_hidden_state\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.10/site-packages/transformers/processing_utils.py:184\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mcls\u001b[39m, pretrained_model_name_or_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    155\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m    Instantiate a processor associated with a pretrained model.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m            [`~tokenization_utils_base.PreTrainedTokenizer.from_pretrained`].\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     args \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_arguments_from_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    185\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.10/site-packages/transformers/processing_utils.py:228\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m         attribute_class \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 228\u001b[0m     args\u001b[39m.\u001b[39mappend(attribute_class\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.10/site-packages/transformers/image_processing_utils.py:165\u001b[0m, in \u001b[0;36mImageProcessingMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     85\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m    Instantiate a type of [`~image_processing_utils.ImageProcessingMixin`] from an image processor.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     image_processor_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_image_processor_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    167\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_dict(image_processor_dict, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.10/site-packages/transformers/image_processing_utils.py:288\u001b[0m, in \u001b[0;36mImageProcessingMixin.get_image_processor_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         \u001b[39m# For any other exception, we throw a generic error.\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load image processor for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m it from \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m same name. Otherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m directory containing a \u001b[39m\u001b[39m{\u001b[39;00mIMAGE_PROCESSOR_NAME\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         )\n\u001b[1;32m    295\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Load image_processor dict\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(resolved_image_processor_file, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m reader:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load image processor for 'dandelin/vilt-b32-mlm'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'dandelin/vilt-b32-mlm' is the correct path to a directory containing a preprocessor_config.json file"
     ]
    }
   ],
   "source": [
    "from transformers import ViltProcessor, ViltModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# prepare image and text\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "text = \"hello world\"\n",
    "\n",
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-mlm\", force_download=True)\n",
    "model = ViltModel.from_pretrained(\"dandelin/vilt-b32-mlm\", force_download=True)\n",
    "\n",
    "# inputs = processor(None, text, return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
